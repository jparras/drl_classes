{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**AlphaZero** is a model-based DRL method, which means that it needs knowledge of the transition and/or the reward for the problem.\n",
        "\n",
        "This algorithm became very popular due to its success in the game of Go. AlphaZero was designed to be used in specific two-player games:\n",
        "* Two-player zero-sum game: it is a generalization of the control situation, where there are more than one agent, known as players. Namely, there must be two players. Zero-sum means that the gains of one player must be the losses of the other, i.e., the game model is of extreme competition. However, it is true that AlphaZero could also be adapted to control problems.\n",
        "* The game must have perfect observability, which means that the state is known to the agent. This rules out poker, for instance, as there is no perfect observability (i.e., a player does not know the cards on the deck nor the cards of the other players).\n",
        "* The game must have deterministic transitions, which means that given a state-action pair, the next state is known.\n",
        "* The agent must know the model (i.e., the rules in a board game such as chess). This assumption was relaxed by its successor algorithm, MuZero.\n",
        "\n",
        "Note that board games are an ideal environment to test AlphaZero: this code illustrates AlphaZero using tic-tac-toe.\n",
        "\n",
        "The three key elements of AlphaZero are:\n",
        "* A neural network, that predicts the optimal value and policy for a given state $(v,\\pi)=f_{\\theta}(s)$.\n",
        "* Monte-Carlo Tree Search (MCTS). AlphaZero builds a tree where each node is a state of the problem, and each edge represents an action. Each edge (i.e., each state-action pair) stores four statistics: $N$ (number of times the state-action pair has been visited), $W$ (the total value of the state-action pair), $Q$ (the mean state-action value, i.e., $W/N$), and $P$ (prior probability of choosing action $a$ in state $s$).\n",
        "\n",
        " MCTS is used to obtain rollouts: for a given state $s$, choose an action $a$ following the Upper Confidence Tree (UCT) algorithm (which balances exploration and exploitation), and repeat the process until a leaf is reached. The leaf may be (1) a final state of the game (i.e., a player wins) or (2) a state not added to the tree yet. In the former case, set the value of the game to the result, and in the latter, to the predicted value of the neural network. Finally, propagate the results to all state-action pairs visited, updating $N$, $W$ and $Q$.\n",
        "\n",
        " Note that the number of rollouts is the *thinking time*: more rollouts mean better results.\n",
        "\n",
        "* A replay memory to update the neural network. Each state-action pair obtained during MCTS is appended to a replay memory, which is used to train the neural network.\n",
        "\n",
        "In a board game, AlphaZero plays against itself (self-play) and learns from scratch. Let us check that in this code!\n",
        "\n",
        "First, let us import all the libraries needed."
      ],
      "metadata": {
        "id": "6r5gNxeFSpkS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GbfmLbHIRLbi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import deque\n",
        "import random\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pickle\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let us create the Tic-tac-toe game. To do that, we define two classes: one for the game, and another for each state (i.e., each board position). Note the similitude to the control environments that we have used before: many of the methods are similar."
      ],
      "metadata": {
        "id": "zxs_6VAWXkmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Game:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.currentPlayer = 1  # Player that moves\n",
        "        self.gameState = GameState(np.array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int), 1)\n",
        "        self.actionSpace = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int)\n",
        "        self.pieces = {'1': 'X', '0': '-', '-1': 'O'}\n",
        "        self.grid_shape = (3, 3)\n",
        "        self.input_shape = (2, 3, 3)\n",
        "        self.name = 'Tic-tac-toe'\n",
        "        self.state_size = len(self.gameState.binary)\n",
        "        self.action_size = len(self.actionSpace)\n",
        "\n",
        "    def reset(self):\n",
        "        self.gameState = GameState(np.array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int), 1)\n",
        "        self.currentPlayer = 1\n",
        "        return self.gameState\n",
        "\n",
        "    def step(self, action):\n",
        "        next_state, value, done = self.gameState.takeAction(action)\n",
        "        self.gameState = next_state\n",
        "        self.currentPlayer = -self.currentPlayer\n",
        "        info = None\n",
        "        return ((next_state, value, done, info))\n",
        "\n",
        "    def identities(self, state, actionValues):\n",
        "        identities = [(state, actionValues)]\n",
        "        currentBoard = state.board\n",
        "        currentAV = actionValues\n",
        "        currentBoard = np.array([\n",
        "            currentBoard[2], currentBoard[1], currentBoard[0]\n",
        "            , currentBoard[5], currentBoard[4], currentBoard[3]\n",
        "            , currentBoard[8], currentBoard[7], currentBoard[6]\n",
        "        ])\n",
        "        currentAV = np.array([\n",
        "            currentAV[2], currentAV[1], currentAV[0]\n",
        "            , currentAV[5], currentAV[4], currentAV[3]\n",
        "            , currentAV[8], currentAV[7], currentAV[6]\n",
        "        ])\n",
        "        identities.append((GameState(currentBoard, state.playerTurn), currentAV))\n",
        "        return identities\n",
        "\n",
        "\n",
        "class GameState():\n",
        "    def __init__(self, board, playerTurn):\n",
        "        self.board = board\n",
        "        self.pieces = {'1': 'X', '0': '-', '-1': 'O'}\n",
        "        self.winners = [  # List of positions that end the game\n",
        "            [0, 1, 2],\n",
        "            [3, 4, 5],\n",
        "            [6, 7, 8],\n",
        "            [0, 3, 6],\n",
        "            [1, 4, 7],\n",
        "            [2, 5, 8],\n",
        "            [0, 4, 8],\n",
        "            [2, 4, 6],\n",
        "        ]\n",
        "        self.playerTurn = playerTurn\n",
        "        self.binary = self._binary()  # Positions occupied by current player (1) and the adversary (-1)\n",
        "        self.id = self._convertStateToId()\n",
        "        self.allowedActions = self._allowedActions()  # Allowed actions are where board is not occupied!\n",
        "        self.isEndGame = self._checkForEndGame()\n",
        "        self.value = self._getValue()\n",
        "        self.score = self._getScore()\n",
        "\n",
        "    def _allowedActions(self):\n",
        "        allowed = []\n",
        "        for i in range(len(self.board)):  # Allowed actions are only the ones where board==0\n",
        "            if self.board[i] == 0:\n",
        "                allowed.append(i)\n",
        "        return allowed\n",
        "\n",
        "    def _binary(self):\n",
        "        currentplayer_position = np.zeros(len(self.board), dtype=int)\n",
        "        currentplayer_position[self.board == self.playerTurn] = 1\n",
        "        other_position = np.zeros(len(self.board), dtype=int)\n",
        "        other_position[self.board == -self.playerTurn] = 1\n",
        "        position = np.append(currentplayer_position, other_position)\n",
        "        return (position)\n",
        "\n",
        "    def _convertStateToId(self):\n",
        "        player1_position = np.zeros(len(self.board), dtype=int)\n",
        "        player1_position[self.board == 1] = 1\n",
        "        other_position = np.zeros(len(self.board), dtype=int)\n",
        "        other_position[self.board == -1] = 1\n",
        "        position = np.append(player1_position, other_position)\n",
        "        id = ''.join(map(str, position))\n",
        "        return id\n",
        "\n",
        "    def _checkForEndGame(self):\n",
        "        if np.count_nonzero(self.board) == 9:\n",
        "            return 1  # All positions in the board are occupied\n",
        "        for x, y, z in self.winners:\n",
        "            if (self.board[x] + self.board[y] + self.board[z] == 3 * -self.playerTurn):\n",
        "                return 1  # A player has won the game\n",
        "        return 0\n",
        "\n",
        "    def _getValue(self):\n",
        "        # This is the value of the state for the current player\n",
        "        # i.e. if the previous player played a winning move, you lose\n",
        "        for x, y, z in self.winners:\n",
        "            if (self.board[x] + self.board[y] + self.board[z] == 3 * -self.playerTurn):\n",
        "                return (-1, -1, 1)\n",
        "        return (0, 0, 0)\n",
        "\n",
        "    def _getScore(self):\n",
        "        tmp = self.value\n",
        "        return (tmp[1], tmp[2])\n",
        "\n",
        "    def takeAction(self, action):\n",
        "        newBoard = np.array(self.board)\n",
        "        newBoard[action] = self.playerTurn\n",
        "        newState = GameState(newBoard, -self.playerTurn)\n",
        "        value = 0\n",
        "        done = 0\n",
        "        if newState.isEndGame:\n",
        "            value = newState.value[0]\n",
        "            done = 1\n",
        "        return (newState, value, done)\n"
      ],
      "metadata": {
        "id": "DAkj0XKHX7h_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let us create the replay memory: again, we will use a queue to store the experience vectors. Short-term memory is used to store experience vectors, which are later moved to the long-term memory for training. This architecture allows for parallel training: one process updates the short-term memory with samples, while another updates the neural network using the long-term memory. Note that this implementation is not parallel, but the memory structure would allow it."
      ],
      "metadata": {
        "id": "XoUz2DZkYFEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Memory:\n",
        "    def __init__(self, memory_size):\n",
        "        self.memory_size = memory_size\n",
        "        self.ltmemory = deque(maxlen=self.memory_size)\n",
        "        self.stmemory = deque(maxlen=self.memory_size)\n",
        "\n",
        "    def commit_stmemory(self, identities, state, actionValues):\n",
        "        for r in identities(state, actionValues):\n",
        "            self.stmemory.append({\n",
        "                'board': r[0].board\n",
        "                , 'state': r[0]\n",
        "                , 'id': r[0].id\n",
        "                , 'AV': r[1]\n",
        "                , 'playerTurn': r[0].playerTurn\n",
        "            })\n",
        "\n",
        "    def commit_ltmemory(self):\n",
        "        for i in self.stmemory:\n",
        "            self.ltmemory.append(i)\n",
        "        self.clear_stmemory()\n",
        "\n",
        "    def clear_stmemory(self):\n",
        "        self.stmemory = deque(maxlen=self.memory_size)"
      ],
      "metadata": {
        "id": "OxhSh4xlYj3H"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we create the two basic structures for our tree: the nodes and the edges, with the information that each one of them stores."
      ],
      "metadata": {
        "id": "oArS2kRHZAkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class mcNode():\n",
        "\n",
        "    def __init__(self, state):\n",
        "        self.state = state\n",
        "        self.playerTurn = state.playerTurn\n",
        "        self.id = state.id\n",
        "        self.edges = []\n",
        "\n",
        "    def isLeaf(self):  # Checks whether the node is a leaf or not\n",
        "        if len(self.edges) > 0:\n",
        "            return False\n",
        "        else:\n",
        "            return True\n",
        "\n",
        "\n",
        "class mcEdge():\n",
        "\n",
        "    def __init__(self, inNode, outNode, prior, action):\n",
        "        self.id = inNode.state.id + '|' + outNode.state.id\n",
        "        self.inNode = inNode\n",
        "        self.outNode = outNode\n",
        "        self.playerTurn = inNode.state.playerTurn\n",
        "        self.action = action\n",
        "\n",
        "        self.stats = {\n",
        "            'N': 0,\n",
        "            'W': 0,\n",
        "            'Q': 0,\n",
        "            'P': prior,\n",
        "        }"
      ],
      "metadata": {
        "id": "yj15Yw5_ZH8u"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And finally, we implement our MCTS method to obtain a rollout, whose two main methods are:\n",
        "* The **moveToLeaf** method starts in the root node, and takes actions following UCT algorithm until a leaf node is found.\n",
        "* The **backfill** method updates all the edge statistics for the edges in a rollout."
      ],
      "metadata": {
        "id": "SWdfMmENZQeG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class mcMCTS():\n",
        "\n",
        "    def __init__(self, root, cpuct, EPSILON, ALPHA):\n",
        "        self.root = root\n",
        "        self.tree = {}\n",
        "        self.cpuct = cpuct\n",
        "        self.addNode(root)\n",
        "        self.EPSILON = EPSILON\n",
        "        self.ALPHA = ALPHA  # Dirichlet noise parameter\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tree)\n",
        "\n",
        "    def moveToLeaf(self):\n",
        "        breadcrumbs = []\n",
        "        currentNode = self.root\n",
        "        done = 0\n",
        "        value = 0\n",
        "        while not currentNode.isLeaf():\n",
        "            maxQU = -99999\n",
        "            if currentNode == self.root:\n",
        "                epsilon = self.EPSILON\n",
        "                nu = np.random.dirichlet([self.ALPHA] * len(currentNode.edges))\n",
        "            else:\n",
        "                epsilon = 0\n",
        "                nu = [0] * len(currentNode.edges)\n",
        "            Nb = 0\n",
        "            for action, edge in currentNode.edges:\n",
        "                Nb = Nb + edge.stats['N']\n",
        "            for idx, (action, edge) in enumerate(currentNode.edges):\n",
        "                U = self.cpuct * \\\n",
        "                    ((1 - epsilon) * edge.stats['P'] + epsilon * nu[idx]) * \\\n",
        "                    np.sqrt(Nb) / (1 + edge.stats['N'])\n",
        "                Q = edge.stats['Q']\n",
        "                if Q + U > maxQU:\n",
        "                    maxQU = Q + U\n",
        "                    simulationAction = action\n",
        "                    simulationEdge = edge\n",
        "            newState, value, done = currentNode.state.takeAction(simulationAction)  # the value of the newState from the POV of the new playerTurn\n",
        "            currentNode = simulationEdge.outNode\n",
        "            breadcrumbs.append(simulationEdge)\n",
        "        return currentNode, value, done, breadcrumbs\n",
        "\n",
        "    def backFill(self, leaf, value, breadcrumbs):\n",
        "        currentPlayer = leaf.state.playerTurn\n",
        "        for edge in breadcrumbs:\n",
        "            playerTurn = edge.playerTurn\n",
        "            if playerTurn == currentPlayer:\n",
        "                direction = 1\n",
        "            else:\n",
        "                direction = -1\n",
        "            edge.stats['N'] = edge.stats['N'] + 1\n",
        "            edge.stats['W'] = edge.stats['W'] + value * direction\n",
        "            edge.stats['Q'] = edge.stats['W'] / edge.stats['N']\n",
        "\n",
        "    def addNode(self, node):\n",
        "        self.tree[node.id] = node\n"
      ],
      "metadata": {
        "id": "z0N36asBZq0D"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we define the neural network model that we are using. As Tic-tac-toe is a simple game, we simply use an MLP, which takes as input the state (i.e., board positions) and returns as output the value and the probability of each action."
      ],
      "metadata": {
        "id": "ocyNxjYOZwut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Gen_Model(nn.Module):  # Simple model for AlphaZero: an MLP\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
        "        super(Gen_Model, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # Prepare all the layers needed\n",
        "        self.l1 = nn.Linear(self.input_dim, self.hidden_dim)\n",
        "        self.l2 = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
        "        self.l3 = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
        "        self.l1_policy = nn.Linear(self.hidden_dim, self.output_dim)\n",
        "        self.l1_value = nn.Linear(self.hidden_dim, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Define forward pass\n",
        "        x = self.relu(self.l1(x))\n",
        "        x = self.relu(self.l2(x))\n",
        "        x = self.relu(self.l3(x))\n",
        "        logits = self.l1_policy(x)\n",
        "        probs = self.softmax(logits)\n",
        "        value = self.l1_value(x)\n",
        "        return value, logits\n"
      ],
      "metadata": {
        "id": "oHeeFAylaLCc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we are finally ready to create our AlphaZero agent, that implements the main algorithm."
      ],
      "metadata": {
        "id": "BPzUzgvQbBIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent():  # Alpha-Zero agent\n",
        "    def __init__(self, name, state_size, action_size, model,\n",
        "                 mcts_simulations=20,  # MCTS simulations: higher is better, but higher computational cost\n",
        "                 cpuct=1,  # Exploration parameter: higher encourages exploration, but lower exploitation\n",
        "                 epsilon=0.2,  # Epsilon value on UCT: higher encourages exploration, but lower exploitation\n",
        "                 alpha=0.8,  # Dirichlet noise parameter value\n",
        "                 training_loops=100,  # Number of batch sampled and trained per training call\n",
        "                 epochs=5,  # Training epochs for a given batch\n",
        "                 batch_size=128,  # Batch size\n",
        "                 device=None  # Device to use for training\n",
        "                 ):\n",
        "        self.name = name\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.cpuct = cpuct\n",
        "        self.MCTSsimulations = mcts_simulations\n",
        "        self.model = model\n",
        "        self.mcts = None\n",
        "        self.train_overall_loss = []\n",
        "        self.train_value_loss = []\n",
        "        self.train_policy_loss = []\n",
        "        self.val_overall_loss = []\n",
        "        self.val_value_loss = []\n",
        "        self.val_policy_loss = []\n",
        "        self.epsilon = epsilon\n",
        "        self.alpha = alpha\n",
        "        self.training_loops = training_loops\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        if device is None:\n",
        "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # To use GPU if available\n",
        "        else:\n",
        "            self.device = device\n",
        "        print('AlphaZero is using device: ', self.device)\n",
        "        # Prepare the optimizer\n",
        "        self.learning_rate = 0.001\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
        "\n",
        "\n",
        "    def simulate(self):\n",
        "        leaf, value, done, breadcrumbs = self.mcts.moveToLeaf()  # Move to leaf\n",
        "        value, breadcrumbs = self.evaluateLeaf(leaf, value, done, breadcrumbs)  # Evaluate the leaf\n",
        "        self.mcts.backFill(leaf, value, breadcrumbs)  # Backfill the value through the tree\n",
        "\n",
        "    def act(self, state, tau):\n",
        "        if self.mcts == None or state.id not in self.mcts.tree:\n",
        "            self.buildMCTS(state)\n",
        "        else:\n",
        "            self.changeRootMCTS(state)\n",
        "        #### run the simulation\n",
        "        for sim in range(self.MCTSsimulations):\n",
        "            self.simulate()\n",
        "        #### get action values\n",
        "        pi, values = self.getAV(1)\n",
        "        ####pick the action\n",
        "        action, value = self.chooseAction(pi, values, tau)\n",
        "        nextState, _, _ = state.takeAction(action)\n",
        "        NN_value = -self.get_preds(nextState)[0]\n",
        "        return (action, pi, value, NN_value)\n",
        "\n",
        "    def predict(self, state):  # Note that this method works only for single states!\n",
        "        preds = self.model(torch.unsqueeze(torch.from_numpy(state).type(torch.float32).to(self.device), 0))\n",
        "        return preds[0].detach().cpu().numpy()[0], preds[1].detach().cpu().numpy()[0]\n",
        "\n",
        "    def get_preds(self, state):\n",
        "        # predict the leaf\n",
        "        preds = self.predict(state.binary)\n",
        "        value, logits = preds[0], preds[1]\n",
        "        allowedActions = state.allowedActions\n",
        "        mask = np.ones(logits.shape, dtype=bool)\n",
        "        mask[allowedActions] = False\n",
        "        logits[mask] = -100\n",
        "        # SOFTMAX\n",
        "        odds = np.exp(logits)\n",
        "        probs = odds / np.sum(odds)\n",
        "        return ((value, probs, allowedActions))\n",
        "\n",
        "    def evaluateLeaf(self, leaf, value, done, breadcrumbs):\n",
        "        if done == 0:\n",
        "            value, probs, allowedActions = self.get_preds(leaf.state)\n",
        "            probs = probs[allowedActions]\n",
        "            for idx, action in enumerate(allowedActions):\n",
        "                newState, _, _ = leaf.state.takeAction(action)\n",
        "                if newState.id not in self.mcts.tree:\n",
        "                    node = mcNode(newState)\n",
        "                    self.mcts.addNode(node)\n",
        "                else:\n",
        "                    node = self.mcts.tree[newState.id]\n",
        "                newEdge = mcEdge(leaf, node, probs[idx], action)\n",
        "                leaf.edges.append((action, newEdge))\n",
        "        return ((value, breadcrumbs))\n",
        "\n",
        "    def getAV(self, tau):\n",
        "        edges = self.mcts.root.edges\n",
        "        pi = np.zeros(self.action_size, dtype=int)\n",
        "        values = np.zeros(self.action_size, dtype=np.float32)\n",
        "        for action, edge in edges:\n",
        "            pi[action] = pow(edge.stats['N'], 1 / tau)\n",
        "            values[action] = edge.stats['Q']\n",
        "        pi = pi / (np.sum(pi) * 1.0)\n",
        "        return pi, values\n",
        "\n",
        "    def chooseAction(self, pi, values, tau):\n",
        "        if tau == 0:\n",
        "            actions = np.argwhere(pi == max(pi))\n",
        "            action = random.choice(actions)[0]\n",
        "        else:\n",
        "            action_idx = np.random.multinomial(1, pi)\n",
        "            action = np.where(action_idx == 1)[0][0]\n",
        "        value = values[action]\n",
        "        return action, value\n",
        "\n",
        "    def replay(self, ltmemory):\n",
        "        for i in range(self.training_loops):\n",
        "            minibatch = random.sample(ltmemory, min(self.batch_size, len(ltmemory)))\n",
        "            training_states = np.array([row['state'].binary for row in minibatch])\n",
        "            value_target = np.array([row['value'] for row in minibatch])\n",
        "            policy_target = np.array([row['AV'] for row in minibatch])\n",
        "            # Train the model\n",
        "            self.model.train()\n",
        "            training_states = torch.from_numpy(training_states).type(torch.float32).to(self.device)\n",
        "            value_target = torch.from_numpy(value_target).type(torch.float32).to(self.device)\n",
        "            policy_target = torch.from_numpy(policy_target).type(torch.float32).to(self.device)\n",
        "\n",
        "            for e in range(self.epochs):\n",
        "                value, logits = self.model(training_states)\n",
        "                value_loss = torch.mean(torch.square(value_target - value))\n",
        "                policy_criterion = nn.CrossEntropyLoss()\n",
        "                logits[policy_target == 0] = -100\n",
        "                policy_loss = policy_criterion(logits, policy_target)\n",
        "                loss = value_loss + policy_loss\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "            self.train_overall_loss.append(round(loss.item(), 4))\n",
        "            self.train_value_loss.append(round(value_loss.item(), 4))\n",
        "            self.train_policy_loss.append(round(policy_loss.item(), 4))\n",
        "\n",
        "    def buildMCTS(self, state):\n",
        "        self.root = mcNode(state)\n",
        "        self.mcts = mcMCTS(self.root, self.cpuct, self.epsilon, self.alpha)\n",
        "\n",
        "    def changeRootMCTS(self, state):\n",
        "        self.mcts.root = self.mcts.tree[state.id]\n"
      ],
      "metadata": {
        "id": "JLCmMomgbQnr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next method is used to play a match between two agents. This allows us to train AlphaZero against itself, to test it against an optimal agent, and even allows you to play against AlphaZero!"
      ],
      "metadata": {
        "id": "chrW0WEgaQjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def playMatches(player1, player2, EPISODES, turns_until_tau0, memory=None, goes_first=0):\n",
        "    env = Game()\n",
        "    scores = {player1.name: 0, \"drawn\": 0, player2.name: 0}\n",
        "    sp_scores = {'sp': 0, \"drawn\": 0, 'nsp': 0}\n",
        "    points = {player1.name: [], player2.name: []}\n",
        "    for e in range(EPISODES):\n",
        "        #print(str(e + 1) + ' ', end='')\n",
        "        state = env.reset()\n",
        "        done = 0\n",
        "        turn = 0\n",
        "        player1.mcts = None\n",
        "        player2.mcts = None\n",
        "        if goes_first == 0:\n",
        "            player1Starts = random.randint(0, 1) * 2 - 1\n",
        "        else:\n",
        "            player1Starts = goes_first\n",
        "        if player1Starts == 1:\n",
        "            players = {1: {\"agent\": player1, \"name\": player1.name}\n",
        "                , -1: {\"agent\": player2, \"name\": player2.name}\n",
        "                       }\n",
        "        else:\n",
        "            players = {1: {\"agent\": player2, \"name\": player2.name}\n",
        "                , -1: {\"agent\": player1, \"name\": player1.name}\n",
        "                       }\n",
        "        while done == 0:\n",
        "            turn = turn + 1\n",
        "            #### Run the MCTS algo and return an action\n",
        "            if turn < turns_until_tau0:\n",
        "                action, pi, MCTS_value, NN_value = players[state.playerTurn]['agent'].act(state, 1)\n",
        "            else:\n",
        "                action, pi, MCTS_value, NN_value = players[state.playerTurn]['agent'].act(state, 0)\n",
        "\n",
        "            if memory != None:\n",
        "                ####Commit the move to memory\n",
        "                memory.commit_stmemory(env.identities, state, pi)\n",
        "            ### Do the action\n",
        "            state, value, done, _ = env.step(\n",
        "                action)  # the value of the newState from the POV of the new playerTurn i.e. -1 if the previous player played a winning move\n",
        "            if done == 1:\n",
        "                if memory != None:\n",
        "                    #### If the game is finished, assign the values correctly to the game moves\n",
        "                    for move in memory.stmemory:\n",
        "                        if move['playerTurn'] == state.playerTurn:\n",
        "                            move['value'] = value\n",
        "                        else:\n",
        "                            move['value'] = -value\n",
        "                    memory.commit_ltmemory()\n",
        "                if value == 1:\n",
        "                    # logger.info('%s WINS!', players[state.playerTurn]['name'])\n",
        "                    scores[players[state.playerTurn]['name']] = scores[players[state.playerTurn]['name']] + 1\n",
        "                    if state.playerTurn == 1:\n",
        "                        sp_scores['sp'] = sp_scores['sp'] + 1\n",
        "                    else:\n",
        "                        sp_scores['nsp'] = sp_scores['nsp'] + 1\n",
        "                elif value == -1:\n",
        "                    # logger.info('%s WINS!', players[-state.playerTurn]['name'])\n",
        "                    scores[players[-state.playerTurn]['name']] = scores[players[-state.playerTurn]['name']] + 1\n",
        "\n",
        "                    if state.playerTurn == 1:\n",
        "                        sp_scores['nsp'] = sp_scores['nsp'] + 1\n",
        "                    else:\n",
        "                        sp_scores['sp'] = sp_scores['sp'] + 1\n",
        "                else:\n",
        "                    # logger.info('DRAW...')\n",
        "                    scores['drawn'] = scores['drawn'] + 1\n",
        "                    sp_scores['drawn'] = sp_scores['drawn'] + 1\n",
        "                pts = state.score\n",
        "                points[players[state.playerTurn]['name']].append(pts[0])\n",
        "                points[players[-state.playerTurn]['name']].append(pts[1])\n",
        "    return (scores, memory, points, sp_scores)"
      ],
      "metadata": {
        "id": "3iWaVCjdaLKp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also use an optimal agent to track the performance of AlphaZero. Note that this agent is **not** used to train AlphaZero, as AlphaZero learns against itself: it is only used to *test* the performance of AlphaZero.\n",
        "\n",
        "The *wget* command is used to download the trained agent from the internet."
      ],
      "metadata": {
        "id": "C4zzGXbzakEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/jparras/drl_classes/raw/main/model_based/oa.zip\n",
        "!unzip /content/oa.zip\n",
        "class Opt_agent():  # Optimal policy obtained (trained using min-max Q-Learning)\n",
        "    def __init__(self, name, state_size, action_size):\n",
        "        self.name = name\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        try:\n",
        "            #self.state_list = np.load('/content/alphazero_states.npy')\n",
        "            #self.pi = np.load('/content/alphazero_pi.npy', allow_pickle=True)\n",
        "            with open('/content/oa.pickle', 'rb') as handle:\n",
        "              b = pickle.load(handle)\n",
        "            self.state_list = b['states']\n",
        "            self.pi = b['pi']\n",
        "            print(\"Optimal agent loaded\")\n",
        "        except:\n",
        "            print(\"Optimal agent couldn't be loaded\")\n",
        "\n",
        "    def act(self, state, tau):\n",
        "        bd = np.copy(state.board)\n",
        "        player = state.playerTurn  # Player that opt agent plays for\n",
        "        bd[bd == -player] = 2\n",
        "        bd[bd == player] = 1\n",
        "        si = np.where(np.all(bd == self.state_list, 1))[0][0]\n",
        "        if type(self.pi[\n",
        "                    si]) is np.ndarray:  # In some states, the optimal policy is not unique (i.e., some actions lead to the highest possible reward)\n",
        "            action = np.random.choice(self.pi[si])\n",
        "        else:\n",
        "            action = self.pi[si]\n",
        "        pi = np.zeros(self.action_size)\n",
        "        pi[action] = 1\n",
        "        value = None\n",
        "        NN_value = None\n",
        "        return (action, pi, value, NN_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApG5oHNcajdj",
        "outputId": "0f4d0540-bf8f-488a-ccfc-263b1139c400"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-26 09:51:01--  https://github.com/jparras/drl_classes/raw/main/model_based/oa.zip\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/jparras/drl_classes/main/model_based/oa.zip [following]\n",
            "--2023-07-26 09:51:01--  https://raw.githubusercontent.com/jparras/drl_classes/main/model_based/oa.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 40429 (39K) [application/zip]\n",
            "Saving to: ‘oa.zip’\n",
            "\n",
            "\roa.zip                0%[                    ]       0  --.-KB/s               \roa.zip              100%[===================>]  39.48K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2023-07-26 09:51:01 (13.3 MB/s) - ‘oa.zip’ saved [40429/40429]\n",
            "\n",
            "Archive:  /content/oa.zip\n",
            "  inflating: oa.pickle               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As usual, we seed everything for reproducibility."
      ],
      "metadata": {
        "id": "Qk6E-fSucSYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ],
      "metadata": {
        "id": "ND9rP_WHcWAj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now it is time to finally train our model! Here is the main loop, which trains our AlphaZero agent from scratch"
      ],
      "metadata": {
        "id": "A8HjkYcNcXdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Self play parameters\n",
        "episodes = 50  # Number of games to self-play per iteration\n",
        "turns_until_tau0 = 4  # turn on which it starts playing deterministically (to enforce exploration)\n",
        "max_num_iter_train = 10  # Number of iterations to train Alpha Zero agent (increasing it improves results, at the cost of a higher training time)\n",
        "matches_eval = 30\n",
        "matches_final_eval = 100\n",
        "\n",
        "# Start environment of the game\n",
        "env = Game()\n",
        "model = Gen_Model(input_dim=2 * np.prod(env.grid_shape), output_dim=env.action_size, hidden_dim=128) # Initialize Neural Network: input is the board state for both players\n",
        "memory = Memory(memory_size=10000)  # Initialize memory\n",
        "agent = Agent('AlphaZero', env.state_size, env.action_size, model, device='cpu')  # Create the agent\n",
        "opt_player = Opt_agent('player_opt', env.state_size, env.action_size)  # Optimal player (to see the Alpha Zero agent evolution)\n",
        "iteration = 0\n",
        "scores_training = []\n",
        "init_time = time.time()\n",
        "\n",
        "while iteration < max_num_iter_train:\n",
        "    iteration += 1\n",
        "    t_iter = time.time()\n",
        "    print('ITERATION ', iteration)\n",
        "\n",
        "    # Self-play\n",
        "    t = time.time()\n",
        "    _, memory, _, _ = playMatches(agent, agent, episodes, turns_until_tau0=turns_until_tau0, memory=memory)\n",
        "    memory.clear_stmemory()\n",
        "    time_self_play = time.time() - t\n",
        "    # Train neural network\n",
        "    t = time.time()\n",
        "    agent.replay(memory.ltmemory)\n",
        "    #memory_samp = random.sample(memory.ltmemory, min(1000, len(memory.ltmemory)))\n",
        "    time_train = time.time() - t\n",
        "    # Evaluate performance\n",
        "    t = time.time()\n",
        "    scoresoa, _, _, _ = playMatches(opt_player, agent, matches_eval, turns_until_tau0=0, memory=None) # Check the performance level against the Optimal agent on 30 matches\n",
        "    time_matches = time.time() - t\n",
        "    scores_training.append(scoresoa)\n",
        "    print('Iteration time:{} (self-play: {}, train: {}, evaluate: {}. Scores:{})' .format(time.time() - t_iter, time_self_play, time_train, time_matches, scoresoa))\n",
        "print('TOTAL TRAINING TIME ', time.time() - init_time, ' seconds')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtVgR9wvcl90",
        "outputId": "5a15fd45-9fe0-481e-9b36-00e818b6b337"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AlphaZero is using device:  cpu\n",
            "Optimal agent loaded\n",
            "ITERATION  1\n",
            "Iteration time:22.98396611213684 (self-play: 19.119601488113403, train: 1.555994987487793, evaluate: 2.3066368103027344. Scores:{'player_opt': 16, 'drawn': 14, 'AlphaZero': 0})\n",
            "ITERATION  2\n",
            "Iteration time:12.45282530784607 (self-play: 8.672216892242432, train: 1.4899101257324219, evaluate: 2.290660858154297. Scores:{'player_opt': 15, 'drawn': 15, 'AlphaZero': 0})\n",
            "ITERATION  3\n",
            "Iteration time:12.573212385177612 (self-play: 8.609990358352661, train: 1.5270159244537354, evaluate: 2.4361655712127686. Scores:{'player_opt': 13, 'drawn': 17, 'AlphaZero': 0})\n",
            "ITERATION  4\n",
            "Iteration time:12.757163524627686 (self-play: 8.86455249786377, train: 1.5602376461029053, evaluate: 2.3323161602020264. Scores:{'player_opt': 13, 'drawn': 17, 'AlphaZero': 0})\n",
            "ITERATION  5\n",
            "Iteration time:16.02734661102295 (self-play: 8.850415229797363, train: 1.5765130519866943, evaluate: 5.60038161277771. Scores:{'player_opt': 13, 'drawn': 17, 'AlphaZero': 0})\n",
            "ITERATION  6\n",
            "Iteration time:14.288824558258057 (self-play: 9.254278659820557, train: 1.5691072940826416, evaluate: 3.464592218399048. Scores:{'player_opt': 12, 'drawn': 18, 'AlphaZero': 0})\n",
            "ITERATION  7\n",
            "Iteration time:13.127436637878418 (self-play: 8.148736715316772, train: 1.7883427143096924, evaluate: 3.1900081634521484. Scores:{'player_opt': 16, 'drawn': 14, 'AlphaZero': 0})\n",
            "ITERATION  8\n",
            "Iteration time:13.88921570777893 (self-play: 8.986481428146362, train: 2.2782671451568604, evaluate: 2.6243884563446045. Scores:{'player_opt': 13, 'drawn': 17, 'AlphaZero': 0})\n",
            "ITERATION  9\n",
            "Iteration time:12.618102073669434 (self-play: 7.8067638874053955, train: 2.2985053062438965, evaluate: 2.5117297172546387. Scores:{'player_opt': 17, 'drawn': 13, 'AlphaZero': 0})\n",
            "ITERATION  10\n",
            "Iteration time:12.908101320266724 (self-play: 8.644642353057861, train: 2.1628975868225098, evaluate: 2.0993103981018066. Scores:{'player_opt': 16, 'drawn': 14, 'AlphaZero': 0})\n",
            "TOTAL TRAINING TIME  143.63140845298767  seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After training, we now test our agent agains the optimal one, and see how it performs. Also, we show the training curve, which is simply the proportion of victories against the optimal agent. In tic-tac-toe, the optimal agent always draws, so do not expect AlphaZero to win agains the optimal agent!"
      ],
      "metadata": {
        "id": "-treXrlMcpyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('FINAL TOURNAMENT AGAINST OA...')\n",
        "scoresoa_final, _, pointsoa_final, sp_scoresoa_final = playMatches(opt_player, agent, matches_final_eval, turns_until_tau0=0, memory=None)\n",
        "print('\\nSCORES')\n",
        "print(scoresoa_final)\n",
        "print('\\n\\n')\n",
        "for label in ['player_opt', 'drawn', 'AlphaZero']:\n",
        "  plt.plot([s[label] for s in scores_training], label=label)\n",
        "plt.xlabel('Training iter')\n",
        "plt.ylabel('Tournament results')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "KiYSkaqic7Ao",
        "outputId": "2d4c0c7b-a85d-4bd5-f0e3-2c3c82476613"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINAL TOURNAMENT AGAINST OA...\n",
            "\n",
            "SCORES\n",
            "{'player_opt': 47, 'drawn': 53, 'AlphaZero': 0}\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And finally, why don't you test yourself against AlphaZero? We now create a *User* agent, that we use to play agains AlphaZero using the command line. Good luck!"
      ],
      "metadata": {
        "id": "3ADAqE53c_2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_tic_tac_toe(values): # Method to print the game\n",
        "    print(\"\\n\")\n",
        "    print(\"\\t     |     |\")\n",
        "    print(\"\\t  {}  |  {}  |  {}\".format(values[0], values[1], values[2]))\n",
        "    print('\\t_____|_____|_____')\n",
        "\n",
        "    print(\"\\t     |     |\")\n",
        "    print(\"\\t  {}  |  {}  |  {}\".format(values[3], values[4], values[5]))\n",
        "    print('\\t_____|_____|_____')\n",
        "\n",
        "    print(\"\\t     |     |\")\n",
        "\n",
        "    print(\"\\t  {}  |  {}  |  {}\".format(values[6], values[7], values[8]))\n",
        "    print(\"\\t     |     |\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "class User():  # A class to play against any player using the command line\n",
        "    def __init__(self, name, state_size, action_size):\n",
        "        self.name = name\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "\n",
        "    def act(self, state, tau):\n",
        "        values = [state.pieces[str(i)] for i in list(state.board)]\n",
        "        print_tic_tac_toe(values)\n",
        "        print('Your pieces are ', state.pieces[str(state.playerTurn)], ' and your opponent pieces are ', state.pieces[str(-state.playerTurn)])\n",
        "        action = int(input('Enter your chosen action (0-8): '))\n",
        "        pi = np.zeros(self.action_size)\n",
        "        pi[action] = 1\n",
        "        value = None\n",
        "        NN_value = None\n",
        "        return (action, pi, value, NN_value)\n",
        "\n",
        "player1 = User('user', env.state_size, env.action_size)\n",
        "# Select the player you wish to play against\n",
        "player2 = opt_player  # Select this to play againts the optimal agent\n",
        "player2 = agent  # Select this to play against the Alpha Zero agent\n",
        "scores, _, _, _ = playMatches(player1, player2, 1, turns_until_tau0=0, memory=None)\n",
        "print(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35LqSkHfdNhr",
        "outputId": "db2c85a4-9c4d-4450-ebfc-b06e7dd305d7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\t     |     |\n",
            "\t  -  |  -  |  -\n",
            "\t_____|_____|_____\n",
            "\t     |     |\n",
            "\t  -  |  -  |  -\n",
            "\t_____|_____|_____\n",
            "\t     |     |\n",
            "\t  -  |  -  |  -\n",
            "\t     |     |\n",
            "\n",
            "\n",
            "Your pieces are  X  and your opponent pieces are  O\n",
            "Enter your chosen action (0-8): 4\n",
            "\n",
            "\n",
            "\t     |     |\n",
            "\t  -  |  -  |  -\n",
            "\t_____|_____|_____\n",
            "\t     |     |\n",
            "\t  O  |  X  |  -\n",
            "\t_____|_____|_____\n",
            "\t     |     |\n",
            "\t  -  |  -  |  -\n",
            "\t     |     |\n",
            "\n",
            "\n",
            "Your pieces are  X  and your opponent pieces are  O\n",
            "Enter your chosen action (0-8): 0\n",
            "\n",
            "\n",
            "\t     |     |\n",
            "\t  X  |  -  |  -\n",
            "\t_____|_____|_____\n",
            "\t     |     |\n",
            "\t  O  |  X  |  -\n",
            "\t_____|_____|_____\n",
            "\t     |     |\n",
            "\t  -  |  -  |  O\n",
            "\t     |     |\n",
            "\n",
            "\n",
            "Your pieces are  X  and your opponent pieces are  O\n",
            "Enter your chosen action (0-8): 6\n",
            "\n",
            "\n",
            "\t     |     |\n",
            "\t  X  |  -  |  O\n",
            "\t_____|_____|_____\n",
            "\t     |     |\n",
            "\t  O  |  X  |  -\n",
            "\t_____|_____|_____\n",
            "\t     |     |\n",
            "\t  X  |  -  |  O\n",
            "\t     |     |\n",
            "\n",
            "\n",
            "Your pieces are  X  and your opponent pieces are  O\n",
            "Enter your chosen action (0-8): 5\n",
            "\n",
            "\n",
            "\t     |     |\n",
            "\t  X  |  -  |  O\n",
            "\t_____|_____|_____\n",
            "\t     |     |\n",
            "\t  O  |  X  |  X\n",
            "\t_____|_____|_____\n",
            "\t     |     |\n",
            "\t  X  |  O  |  O\n",
            "\t     |     |\n",
            "\n",
            "\n",
            "Your pieces are  X  and your opponent pieces are  O\n",
            "Enter your chosen action (0-8): 1\n",
            "{'user': 0, 'drawn': 1, 'AlphaZero': 0}\n"
          ]
        }
      ]
    }
  ]
}